# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=magnetic-join

# YARN
yarn.package.path=hdfs://magnetic-hadoop-dev/user/stanislav/samza/${project.artifactId}-${pom.version}-dist.tar.gz
# Amount of containers <= partitions in the topic
yarn.container.count=30

# Task
task.class=com.magnetic.streaming.samza.MagneticJoinStreamsTask
task.inputs=kafka.imp-meta,kafka.bid-meta
# Call the window() method every hour (actual window size defined in window method)
task.window.ms=3600000
# Declare that we want our job's checkpoints to be written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.checkpoint.replication.factor=1
# By default, a checkpoint is written every 60 seconds. You can change this if you like.
task.commit.ms=10000

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory

# Kafka System
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.key.serde=string
systems.kafka.samza.msg.serde=json
systems.kafka.consumer.zookeeper.connect=zk001.dev.us-east-1.mgnt.cc:2181/
systems.kafka.producer.bootstrap.servers=kfk001.dev.us-east-1.mgnt.cc:9092

# KV Store
stores.imp-store.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.imp-store.changelog=kafka.imp-store-changelog
stores.imp-store.changelog.replication.factor=1
stores.imp-store.key.serde=string
stores.imp-store.msg.serde=json

stores.bid-store.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.bid-store.changelog=kafka.bid-store-changelog
stores.bid-store.changelog.replication.factor=1
stores.bid-store.key.serde=string
stores.bid-store.msg.serde=json

# Job Coordinator
job.coordinator.system=kafka
job.coordinator.replication.factor=1
